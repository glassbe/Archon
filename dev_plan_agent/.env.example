# Base URL for the OpenAI instance (default is https://api.openai.com/v1)
# OpenAI: https://api.openai.com/v1
# Ollama (example): http://localhost:11434/v1
# OpenRouter: https://openrouter.ai/api/v1
BASE_URL=https://api.openai.com/v1

# OpenAI API Configuration
# Get your OpenAI API Key from https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic API Configuration (optional)
# Get your Anthropic API Key from https://console.anthropic.com/settings/keys
# ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Model Configuration
# The LLM you want to use for the reasoner (analyzing project requirements)
# Example: gpt-4o-mini, gpt-4, claude-3-haiku-20240307
REASONER_MODEL=gpt-4o-mini

# The LLM you want to use for the primary agent/planner
# Example: gpt-4o, gpt-4-turbo, claude-3-opus-20240229
PRIMARY_MODEL=gpt-4o-mini

# LangChain API Key for LangSmith tracing (optional)
# Get your key from https://smith.langchain.com/
# LANGCHAIN_API_KEY=your_langchain_api_key

# Service Configuration
# Port for the FastAPI service
SERVICE_PORT=8200

# Logging configuration
LOG_LEVEL=INFO
